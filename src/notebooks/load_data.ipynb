{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import logging\n",
    "import os\n",
    "\n",
    "# Basic logging setup\n",
    "logging.basicConfig(level=logging.INFO, format=\"%(asctime)s - %(levelname)s - %(message)s\")\n",
    "\n",
    "def load_json(file_path):\n",
    "    if not os.path.exists(file_path):\n",
    "        logging.error(f\"File not found: {file_path}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "    try:\n",
    "        return pd.read_json(file_path, lines=True)\n",
    "    except ValueError as e:\n",
    "        logging.error(f\"Failed to load data from {file_path}: {e}\")\n",
    "        return pd.DataFrame()\n",
    "    except Exception as e:\n",
    "        logging.error(f\"An unexpected error occurred: {e}\")\n",
    "        return pd.DataFrame()\n",
    "\n",
    "def load_data():\n",
    "    \"\"\"\n",
    "    Loads data into pandas DataFrames from JSON files specified in environment variables or defaults.\n",
    "    \n",
    "    Returns: \n",
    "        combined_full_channel (pd.DataFrame): Concatenated DataFrame for FullChannel data.\n",
    "        combined_ticker (pd.DataFrame): Concatenated DataFrame for Ticker data.\n",
    "    \"\"\"\n",
    "    # Environment variables for file paths or default paths\n",
    "    full_channel_files = os.getenv(\"FULL_CHANNEL_FILES\", \"../data/raw/FullChannel_GDAX_20220511_17hr.json,../data/raw/FullChannel_GDAX_20220511_19hr.json,../data/raw/FullChannel_GDAX_20220511_20hr.json\").split(\",\")\n",
    "    ticker_files = os.getenv(\"TICKER_FILES\", \"../data/raw/Ticker_GDAX_20220511_17hr.json,../data/raw/Ticker_GDAX_20220511_19hr.json,../data/raw/Ticker_GDAX_20220511_20hr.json\").split(\",\")\n",
    "\n",
    "    full_channel_data = [load_json(file) for file in full_channel_files if os.path.exists(file)]\n",
    "    ticker_data = [load_json(file) for file in ticker_files if os.path.exists(file)]\n",
    "\n",
    "    # Concatenate data\n",
    "    combined_full_channel = pd.concat(full_channel_data, ignore_index=True) if full_channel_data else pd.DataFrame()\n",
    "    combined_ticker = pd.concat(ticker_data, ignore_index=True) if ticker_data else pd.DataFrame()\n",
    "\n",
    "    if combined_full_channel.empty:\n",
    "        logging.warning(\"No FullChannel data loaded.\")\n",
    "    else:\n",
    "        logging.info(f\"Loaded FullChannel data with {combined_full_channel.shape[0]} rows and {combined_full_channel.shape[1]} columns.\")\n",
    "\n",
    "    if combined_ticker.empty:\n",
    "        logging.warning(\"No Ticker data loaded.\")\n",
    "    else:\n",
    "        logging.info(f\"Loaded Ticker data with {combined_ticker.shape[0]} rows and {combined_ticker.shape[1]} columns.\")\n",
    "\n",
    "    return combined_full_channel, combined_ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-04-30 19:24:28,016 - INFO - Loaded FullChannel data with 1774678 rows and 18 columns.\n",
      "2024-04-30 19:24:28,016 - INFO - Loaded Ticker data with 102805 rows and 15 columns.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                               order_id order_type      size  price  \\\n",
      "0  04074a2a-ff4d-40f8-a921-d88ece5d1562      limit   281.146   2.06   \n",
      "1  04074a2a-ff4d-40f8-a921-d88ece5d1562        NaN       NaN   2.06   \n",
      "2  0299ed2d-d33d-4313-a1d4-b74ce9cc9f26      limit  2324.238   2.33   \n",
      "3                                   NaN        NaN   374.806   2.33   \n",
      "4  474813db-2329-4aba-a07b-b1adea78da8f        NaN       NaN   2.33   \n",
      "\n",
      "                             client_oid      type  side product_id  \\\n",
      "0  0278c289-d977-44e0-9b3a-ff4e82b8dda5  received   buy  WLUNA-USD   \n",
      "1                                   NaN      open   buy  WLUNA-USD   \n",
      "2  b1f276a7-e271-4c82-9fa7-a55451507f82  received  sell  WLUNA-USD   \n",
      "3                                   NaN     match   buy  WLUNA-USD   \n",
      "4                                   NaN      done   buy  WLUNA-USD   \n",
      "\n",
      "                          time    sequence  remaining_size   trade_id  \\\n",
      "0  2022-05-11T15:59:00.796073Z  1292598749             NaN        NaN   \n",
      "1  2022-05-11T15:59:00.796073Z  1292598750         281.146        NaN   \n",
      "2  2022-05-11T15:59:00.813739Z  1292598751             NaN        NaN   \n",
      "3  2022-05-11T15:59:00.813739Z  1292598752             NaN  7884080.0   \n",
      "4  2022-05-11T15:59:00.813739Z  1292598753           0.000        NaN   \n",
      "\n",
      "                         maker_order_id                        taker_order_id  \\\n",
      "0                                   NaN                                   NaN   \n",
      "1                                   NaN                                   NaN   \n",
      "2                                   NaN                                   NaN   \n",
      "3  474813db-2329-4aba-a07b-b1adea78da8f  0299ed2d-d33d-4313-a1d4-b74ce9cc9f26   \n",
      "4                                   NaN                                   NaN   \n",
      "\n",
      "   reason  funds  old_size  new_size  \n",
      "0     NaN    NaN       NaN       NaN  \n",
      "1     NaN    NaN       NaN       NaN  \n",
      "2     NaN    NaN       NaN       NaN  \n",
      "3     NaN    NaN       NaN       NaN  \n",
      "4  filled    NaN       NaN       NaN  \n"
     ]
    }
   ],
   "source": [
    "full_channel, ticker = load_data()\n",
    "\n",
    "print(full_channel.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     type    sequence product_id  price  open_24h    volume_24h  low_24h  \\\n",
      "0  ticker  1292614427  WLUNA-USD   2.42      31.4  3.773185e+07     0.95   \n",
      "1  ticker  1292614429  WLUNA-USD   2.42      31.4  3.773188e+07     0.95   \n",
      "2  ticker  1292614431  WLUNA-USD   2.42      31.4  3.773190e+07     0.95   \n",
      "3  ticker  1292614433  WLUNA-USD   2.42      31.4  3.773217e+07     0.95   \n",
      "4  ticker  1292614468  WLUNA-USD   2.44      31.4  3.773217e+07     0.95   \n",
      "\n",
      "   high_24h    volume_30d  best_bid  best_ask  side  \\\n",
      "0      32.7  5.215304e+07      2.42      2.44  sell   \n",
      "1      32.7  5.215306e+07      2.42      2.44  sell   \n",
      "2      32.7  5.215308e+07      2.42      2.44  sell   \n",
      "3      32.7  5.215335e+07      2.42      2.44  sell   \n",
      "4      32.7  5.215335e+07      2.42      2.44   buy   \n",
      "\n",
      "                          time  trade_id  last_size  \n",
      "0  2022-05-11T15:59:59.959016Z   7884870     11.525  \n",
      "1  2022-05-11T15:59:59.959016Z   7884871     28.646  \n",
      "2  2022-05-11T15:59:59.959016Z   7884872     14.000  \n",
      "3  2022-05-11T15:59:59.959016Z   7884873    274.088  \n",
      "4  2022-05-11T16:00:00.215969Z   7884874      1.100  \n"
     ]
    }
   ],
   "source": [
    "print(ticker.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the combined data frames\n",
    "full_channel.to_csv(\"../data/raw/full_channel.csv\", index=False)\n",
    "ticker.to_csv(\"../data/raw/ticker.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "spoof",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
